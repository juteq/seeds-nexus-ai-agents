{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f08303",
   "metadata": {},
   "source": [
    "# Academic PDF Semantic Search with Chroma\n",
    "\n",
    "Build a semantic search system for academic PDFs using:\n",
    "- **LangChain** for document processing\n",
    "- **OpenAI embeddings** for vectors\n",
    "- **Chroma** for in-memory vector storage\n",
    "- **Q&A system** for natural language queries\n",
    "\n",
    "Load PDFs from arXiv, URLs, or local files → Split into chunks → Generate embeddings → Search and ask questions!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda366c",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "Install required packages for PDF processing and semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-core langchain-openai langchain-community langchain-text-splitters\n",
    "!pip install openai chromadb pypdf pymupdf arxiv tiktoken python-dotenv requests tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f63261",
   "metadata": {},
   "source": [
    "## Setup API Key\n",
    "\n",
    "**Get your OpenAI API key**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "\n",
    "For Colab: Use Secrets (🔑 icon) | For Local: Create `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Detect environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"🔗 Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"💻 Running locally\")\n",
    "\n",
    "# Setup API key based on environment\n",
    "if IN_COLAB:\n",
    "    # Google Colab: Try to get from secrets, fallback to manual input\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        openai_api_key = userdata.get('OPENAI_API_KEY')\n",
    "        if openai_api_key:\n",
    "            os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "            print(\"✅ API key loaded from Colab secrets!\")\n",
    "        else:\n",
    "            print(\"⚠️ No OPENAI_API_KEY found in Colab secrets\")\n",
    "            from getpass import getpass\n",
    "            os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "            print(\"✅ API key set manually!\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not access Colab secrets: {e}\")\n",
    "        from getpass import getpass\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "        print(\"✅ API key set manually!\")\n",
    "else:\n",
    "    # Local environment: Try .env file, then environment variables\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"✅ API key loaded from .env file\")\n",
    "        else:\n",
    "            print(\"⚠️ No API key found in .env file\")\n",
    "            # Check environment variables\n",
    "            if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "                print(\"✅ API key found in environment variables\")\n",
    "            else:\n",
    "                print(\"❌ No API key found. Please set OPENAI_API_KEY\")\n",
    "    except ImportError:\n",
    "        # No python-dotenv, check environment variables\n",
    "        if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "            print(\"✅ API key found in environment variables\")\n",
    "        else:\n",
    "            print(\"❌ No API key found. Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "# Final check\n",
    "if os.environ.get(\"OPENAI_API_KEY\") and os.environ.get(\"OPENAI_API_KEY\") != \"your-api-key-here\":\n",
    "    print(\"🚀 Ready to go!\")\n",
    "else:\n",
    "    print(\"⚠️ Please set your OpenAI API key before continuing!\")\n",
    "    print(\"   • Colab: Add OPENAI_API_KEY to secrets (🔑 icon)\")\n",
    "    print(\"   • Local: Set environment variable or create .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294fab8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7969fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader, ArxivLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import time, requests, json\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"✅ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48129443",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "\n",
    "# Initialize components\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "chat_model = ChatOpenAI(model=CHAT_MODEL, temperature=0.1)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "vectorstore = None  # Will be created when adding documents\n",
    "\n",
    "print(\"✅ Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6cb11",
   "metadata": {},
   "source": [
    "## Initialize Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d531550",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Chroma ready! (in-memory vector database)\")\n",
    "print(\"  - No external setup needed\")\n",
    "print(\"  - Will be created when documents are added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea5c85",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f71a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arxiv_papers(queries: List[str], max_docs: int = 3) -> List[Document]:\n",
    "    \"\"\"Load papers from arXiv.\"\"\"\n",
    "    documents = []\n",
    "    for query in queries:\n",
    "        print(f\"🔍 Searching arXiv: {query}\")\n",
    "        try:\n",
    "            loader = ArxivLoader(query=query, load_max_docs=max_docs)\n",
    "            docs = loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata['search_query'] = query\n",
    "                doc.metadata['source'] = 'arxiv'\n",
    "            documents.extend(docs)\n",
    "            print(f\"  ✅ Found {len(docs)} papers\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {e}\")\n",
    "    return documents\n",
    "\n",
    "def load_pdf_from_url(url: str, title: str = None) -> List[Document]:\n",
    "    \"\"\"Load PDF from URL.\"\"\"\n",
    "    try:\n",
    "        print(f\"📥 Loading PDF: {url}\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        temp_path = \"/tmp/temp_paper.pdf\"\n",
    "        with open(temp_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        loader = PyPDFLoader(temp_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        for doc in documents:\n",
    "            doc.metadata.update({'source': 'url', 'url': url})\n",
    "            if title:\n",
    "                doc.metadata['title'] = title\n",
    "\n",
    "        print(f\"  ✅ Loaded {len(documents)} pages\")\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_local_pdf(file_path: str) -> List[Document]:\n",
    "    \"\"\"Load PDF from local file.\"\"\"\n",
    "    try:\n",
    "        print(f\"📄 Loading: {file_path}\")\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        for doc in documents:\n",
    "            doc.metadata.update({'source': 'local', 'file_path': file_path})\n",
    "\n",
    "        print(f\"  ✅ Loaded {len(documents)} pages\")\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"✅ Document loaders ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af63b17",
   "metadata": {},
   "source": [
    "## Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ac947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_documents(documents: List[Document]) -> int:\n",
    "    \"\"\"Process documents and store in Chroma.\"\"\"\n",
    "    global vectorstore\n",
    "\n",
    "    if not documents:\n",
    "        return 0\n",
    "\n",
    "    print(f\"📝 Processing {len(documents)} documents...\")\n",
    "\n",
    "    # Split into chunks\n",
    "    all_chunks = []\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    print(f\"✂️ Created {len(all_chunks)} chunks\")\n",
    "\n",
    "    try:\n",
    "        if vectorstore is None:\n",
    "            vectorstore = Chroma.from_documents(documents=all_chunks, embedding=embeddings)\n",
    "        else:\n",
    "            vectorstore.add_documents(all_chunks)\n",
    "\n",
    "        print(f\"✅ Stored {len(all_chunks)} chunks\")\n",
    "        return len(all_chunks)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "def search_similar_documents(query: str, k: int = 5) -> List[Document]:\n",
    "    \"\"\"Search for similar documents.\"\"\"\n",
    "    if vectorstore is None:\n",
    "        return []\n",
    "    return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "print(\"✅ Processing functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8515cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore():\n",
    "    \"\"\"Get the current vectorstore.\"\"\"\n",
    "    global vectorstore\n",
    "    if vectorstore is None:\n",
    "        raise ValueError(\"No vectorstore available. Process documents first.\")\n",
    "    return vectorstore\n",
    "\n",
    "def get_vectorstore_stats() -> Dict:\n",
    "    \"\"\"Get statistics about the current vectorstore.\"\"\"\n",
    "    global vectorstore\n",
    "    if vectorstore is None:\n",
    "        return {\"status\": \"empty\", \"total_documents\": 0}\n",
    "\n",
    "    try:\n",
    "        # Get collection info\n",
    "        collection = vectorstore._collection\n",
    "        count = collection.count()\n",
    "\n",
    "        # Try to get embedding dimension\n",
    "        embedding_dim = None\n",
    "        if count > 0:\n",
    "            sample = collection.peek(limit=1)\n",
    "            if sample and 'embeddings' in sample and sample['embeddings']:\n",
    "                embedding_dim = len(sample['embeddings'][0])\n",
    "\n",
    "        return {\n",
    "            \"status\": \"ready\",\n",
    "            \"total_documents\": count,\n",
    "            \"embedding_dimension\": embedding_dim\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error\": str(e), \"total_documents\": 0}\n",
    "\n",
    "print(\"✅ Utility functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761148f2",
   "metadata": {},
   "source": [
    "## Demo: Load Sample Papers\n",
    "\n",
    "Load sample papers from arXiv for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9849f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search queries for academic papers\n",
    "search_queries = [\n",
    "    \"transformer neural networks attention mechanism\",\n",
    "    \"large language models GPT BERT\",\n",
    "    \"computer vision deep learning CNN\"\n",
    "]\n",
    "\n",
    "# Load papers from arXiv\n",
    "print(\"🚀 Loading academic papers from arXiv...\\n\")\n",
    "sample_documents = load_arxiv_papers(search_queries, max_docs=2)\n",
    "\n",
    "print(f\"\\n📚 Total documents loaded: {len(sample_documents)}\")\n",
    "\n",
    "# Display information about loaded papers\n",
    "if sample_documents:\n",
    "    print(\"\\n📋 Loaded Papers:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i, doc in enumerate(sample_documents, 1):\n",
    "        title = doc.metadata.get('Title', 'Unknown Title')\n",
    "        authors = doc.metadata.get('Authors', 'Unknown Authors')\n",
    "        published = doc.metadata.get('Published', 'Unknown Date')\n",
    "\n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Authors: {authors}\")\n",
    "        print(f\"   Published: {published}\")\n",
    "        print(f\"   Content length: {len(doc.page_content)} characters\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"⚠️ No documents were loaded. This might be due to API limits or network issues.\")\n",
    "    print(\"You can try again later or add your own PDF files using the functions above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8fc29",
   "metadata": {},
   "source": [
    "## Demo: Process and Store\n",
    "\n",
    "Process documents and store in Chroma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10936040",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_documents:\n",
    "    # Process and store documents\n",
    "    stored_count = process_and_store_documents(sample_documents)\n",
    "\n",
    "    # Get vectorstore stats\n",
    "    stats = get_vectorstore_stats()\n",
    "\n",
    "    print(f\"\\n📊 Vectorstore Statistics:\")\n",
    "    print(f\"  - Status: {stats['status']}\")\n",
    "    print(f\"  - Documents stored this session: {stored_count}\")\n",
    "    if stats['status'] == 'ready':\n",
    "        print(f\"  - Storage: In-memory Chroma database\")\n",
    "        print(f\"  - Embedding dimension: {stats['embedding_dimension']}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ No documents to process. Please load some documents first.\")\n",
    "    stored_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c7235",
   "metadata": {},
   "source": [
    "## Demo: Semantic Search\n",
    "\n",
    "Test semantic search functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic search\n",
    "if stored_count > 0:\n",
    "    print(\"🔍 Testing Semantic Search\\n\")\n",
    "\n",
    "    # Example search queries\n",
    "    test_queries = [\n",
    "        \"What is attention mechanism in neural networks?\",\n",
    "        \"How do transformers work?\",\n",
    "        \"Computer vision applications\",\n",
    "        \"Deep learning architectures\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"Query: '{query}'\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        try:\n",
    "            # Search for similar documents\n",
    "            results = search_similar_documents(query, k=3)\n",
    "\n",
    "            if results:\n",
    "                for i, result in enumerate(results, 1):\n",
    "                    title = result.metadata.get('Title', 'Unknown Title')\n",
    "                    content_preview = result.page_content[:200] + \"...\"\n",
    "\n",
    "                    print(f\"{i}. From: {title}\")\n",
    "                    print(f\"   Content: {content_preview}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"   No results found\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "        print(\"=\" * 60)\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ No documents in the index. Please load and process documents first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0950678",
   "metadata": {},
   "source": [
    "## Q&A System\n",
    "\n",
    "Build question-answering system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_system() -> RetrievalQA:\n",
    "    \"\"\"Create Q&A system using the vector database.\"\"\"\n",
    "    vectorstore = get_vectorstore()\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=chat_model,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "        return_source_documents=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def ask_question(qa_chain: RetrievalQA, question: str) -> Dict:\n",
    "    \"\"\"Ask a question and get answer with sources.\"\"\"\n",
    "    try:\n",
    "        result = qa_chain({\"query\": question})\n",
    "        return {\n",
    "            \"answer\": result[\"result\"],\n",
    "            \"sources\": result[\"source_documents\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {e}\", \"sources\": []}\n",
    "\n",
    "# Create Q&A system\n",
    "if stored_count > 0:\n",
    "    print(\"🤖 Creating Q&A system...\")\n",
    "    qa_system = create_qa_system()\n",
    "    print(\"✅ Q&A system ready!\")\n",
    "else:\n",
    "    print(\"⚠️ Load documents first.\")\n",
    "    qa_system = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dbfff",
   "metadata": {},
   "source": [
    "## Demo: Q&A\n",
    "\n",
    "Test the question-answering system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d358c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qa_system:\n",
    "    print(\"🤔 Testing Question Answering System\\n\")\n",
    "\n",
    "    # Example questions\n",
    "    questions = [\n",
    "        \"What is the attention mechanism and how does it work?\",\n",
    "        \"What are the main advantages of transformer architectures?\",\n",
    "        \"How do large language models like GPT work?\",\n",
    "        \"What are the key components of computer vision systems?\",\n",
    "        \"What are some applications of deep learning in different domains?\"\n",
    "    ]\n",
    "\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"Question {i}: {question}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Get answer\n",
    "        result = ask_question(qa_system, question)\n",
    "\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "\n",
    "        # Show sources\n",
    "        if result['sources']:\n",
    "            print(f\"\\nSources ({len(result['sources'])} documents):\")\n",
    "            for j, source in enumerate(result['sources'][:3], 1):  # Show top 3 sources\n",
    "                title = source.metadata.get('Title', 'Unknown Title')\n",
    "                print(f\"  {j}. {title}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Q&A system not available. Please load documents first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc76d1",
   "metadata": {},
   "source": [
    "## Ask Your Questions\n",
    "\n",
    "Interactive Q&A with your papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bfeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qa_system:\n",
    "    # Ask your own question\n",
    "    your_question = input(\"Enter your question about the academic papers: \")\n",
    "\n",
    "    if your_question.strip():\n",
    "        print(f\"\\n🤔 Question: {your_question}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        result = ask_question(qa_system, your_question)\n",
    "\n",
    "        print(f\"🤖 Answer: {result['answer']}\")\n",
    "\n",
    "        if result['sources']:\n",
    "            print(f\"\\n📚 Based on {len(result['sources'])} source documents:\")\n",
    "            for i, source in enumerate(result['sources'][:3], 1):\n",
    "                title = source.metadata.get('Title', 'Unknown Title')\n",
    "                print(f\"  {i}. {title}\")\n",
    "    else:\n",
    "        print(\"No question entered.\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Q&A system not available. Please load documents first.\")\n",
    "    print(\"\\nTo use this system:\")\n",
    "    print(\"1. Make sure you have valid API keys\")\n",
    "    print(\"2. Run the document loading cells\")\n",
    "    print(\"3. Process and store the documents\")\n",
    "    print(\"4. Then try asking questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49062320",
   "metadata": {},
   "source": [
    "## Advanced Functions\n",
    "\n",
    "Additional utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_pdf(pdf_path_or_url: str, title: str = None) -> int:\n",
    "    \"\"\"\n",
    "    Add a custom PDF to the knowledge base.\n",
    "\n",
    "    Args:\n",
    "        pdf_path_or_url: Local path or URL to PDF\n",
    "        title: Optional title for the document\n",
    "\n",
    "    Returns:\n",
    "        Number of chunks stored\n",
    "    \"\"\"\n",
    "    if pdf_path_or_url.startswith('http'):\n",
    "        documents = load_pdf_from_url(pdf_path_or_url, title)\n",
    "    else:\n",
    "        documents = load_local_pdf(pdf_path_or_url)\n",
    "        if title and documents:\n",
    "            for doc in documents:\n",
    "                doc.metadata['title'] = title\n",
    "\n",
    "    if documents:\n",
    "        return process_and_store_documents(documents)\n",
    "    return 0\n",
    "\n",
    "def search_papers_by_topic(topic: str, max_papers: int = 5) -> int:\n",
    "    \"\"\"\n",
    "    Search and add papers from arXiv on a specific topic.\n",
    "\n",
    "    Args:\n",
    "        topic: Research topic to search for\n",
    "        max_papers: Maximum number of papers to add\n",
    "\n",
    "    Returns:\n",
    "        Number of chunks stored\n",
    "    \"\"\"\n",
    "    documents = load_arxiv_papers([topic], max_docs=max_papers)\n",
    "\n",
    "    if documents:\n",
    "        return process_and_store_documents(documents)\n",
    "    return 0\n",
    "\n",
    "def get_current_statistics() -> Dict:\n",
    "    \"\"\"\n",
    "    Get current statistics about the Chroma vectorstore.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with vectorstore statistics\n",
    "    \"\"\"\n",
    "    return get_vectorstore_stats()\n",
    "\n",
    "def clear_vectorstore():\n",
    "    \"\"\"\n",
    "    Clear all documents from the Chroma vectorstore.\n",
    "    ⚠️ WARNING: This will delete all stored documents!\n",
    "    \"\"\"\n",
    "    global vectorstore\n",
    "\n",
    "    confirmation = input(\"Are you sure you want to clear ALL documents? Type 'yes' to confirm: \")\n",
    "    if confirmation.lower() == 'yes':\n",
    "        vectorstore = None\n",
    "        print(\"✅ Vectorstore cleared successfully!\")\n",
    "    else:\n",
    "        print(\"❌ Operation cancelled.\")\n",
    "\n",
    "print(\"✅ Advanced functions defined!\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"- add_custom_pdf(pdf_path_or_url, title): Add your own PDF\")\n",
    "print(\"- search_papers_by_topic(topic, max_papers): Search arXiv for specific topics\")\n",
    "print(\"- get_current_statistics(): View current vectorstore stats\")\n",
    "print(\"- clear_vectorstore(): Clear all documents (use with caution!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da45fc8",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Try these advanced features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Add papers on a specific topic\n",
    "# Uncomment and modify the topic as needed\n",
    "# topic = \"quantum computing machine learning\"\n",
    "# stored = search_papers_by_topic(topic, max_papers=2)\n",
    "# print(f\"Added {stored} chunks from papers on '{topic}'\")\n",
    "\n",
    "# Example 2: Add a PDF from URL\n",
    "# Uncomment and replace with an actual PDF URL\n",
    "# pdf_url = \"https://example.com/paper.pdf\"\n",
    "# stored = add_custom_pdf(pdf_url, \"Custom Paper Title\")\n",
    "# print(f\"Added {stored} chunks from custom PDF\")\n",
    "\n",
    "# Example 3: Check current vectorstore statistics\n",
    "if stored_count > 0:\n",
    "    stats = get_current_statistics()\n",
    "    print(\"📊 Current Vectorstore Statistics:\")\n",
    "    print(f\"  - Status: {stats['status']}\")\n",
    "    print(f\"  - Total documents: {stats['total_documents']}\")\n",
    "    if 'embedding_dimension' in stats:\n",
    "        print(f\"  - Embedding dimension: {stats['embedding_dimension']}\")\n",
    "else:\n",
    "    print(\"Vectorstore is empty. Load some documents first!\")\n",
    "\n",
    "# Example 4: Interactive topic search\n",
    "# Uncomment to allow user input\n",
    "# topic = input(\"Enter a research topic to search for papers: \")\n",
    "# if topic.strip():\n",
    "#     stored = search_papers_by_topic(topic, max_papers=3)\n",
    "#     print(f\"Added {stored} chunks from papers on '{topic}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12173593",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Complete PDF semantic search system ready!**\n",
    "\n",
    "**Features**: Load PDFs → Chunk & embed → Search & Q&A  \n",
    "**Stack**: LangChain + OpenAI + Chroma (in-memory)  \n",
    "**Sources**: arXiv, URLs, local files\n",
    "\n",
    "**Next**: Add more papers, customize settings, build apps!\n",
    "\n",
    "📚 [LangChain Docs](https://docs.langchain.com/) | 🤖 [OpenAI API](https://platform.openai.com/docs) | 🔍 [Chroma Docs](https://docs.trychroma.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
